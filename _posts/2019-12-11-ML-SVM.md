---
layout: post
title: "SVM"
date: 2019-12-01 22:29:53 +0900
permalink: /ML/SVM/
header-includes:
- \usepackage{amsmath}
- \usepackage{mathtools}
---
Roadmap:
- [Functional & Geometric Margins](#margin)
- [Lagrange Duality](#lagrange)
    - [KKT Conditions](#KKT)

## Intro

- Problem with Classification:
    
    <center><img src="../../images/ML/SVM1.png" width="300"/></center>
    
    This is a binary classification. The circles & crosses are training examples with two different labels. The black line is the classifier, and it is able to classify "circle" and "cross". For points like $\text{A}$ that are distant from the classifier, we are quite confident that they belong to "cross".
    
    However, what about $\text{B}$ and $\text{C}$ that are super close to the decision boundary? Based on this classifier, $\text{B}$ belongs to "cross" and $\text{C}$ belongs to "circle", but how confident are we about our classifier? What if our classifier is just slightly off and $\text{C}$ was actually "cross"?
    
    <center><img src="../../images/ML/SVM2.png" width="300"/></center>
    
    This, is SVM in a nutshell.

&emsp;<a name="margin"></a> 
## Margins
    
- **Functional Margin**

    $$\begin{equation}
    \hat{\gamma}^{(i)}=y^{(i)}(w^Tx+b)\ \ \ \ \ \ \|\ y\in\{-1,1\}
    \end{equation}$$

    - Intuition: $\hat{\gamma}^{(i)}\uparrow\uparrow\ \rightarrow\text{confidence}\uparrow\uparrow$
    
    - When $y=1\ \rightarrow w^Tx+b \>\> 0$.  
        When $y=-1\\rightarrow w^Tx+b \<\< 0$.
    
    - Problem with functional margin:
    
      if $w\rightarrow kw$ and $b\rightarrow kb$ (where $k>0$), then $g(w^Tx+b)=g(k(w^Tx+b))$
    
      but our $g(z)$ here follows:
      
      $$g(z)=\begin{cases}
      -1& \text{if $z<0$} \\
      1& \text{if $z>0$} \\
      \end{cases}$$
      
      that is, $z$ and $kz$ makes no difference for $g(z)$.
      
      HOWEVER, the functional margin does change by a factor of $k$ here, meaning that a large functional margin does not necessarily represent a confident prediction in this case.
    
    &emsp;
      
- **Geometric Margin**

    Refer back to the figure above. If we want to find the distance between point $A$ and the decision boundary, which is $AA'=\gamma^{(i)}$, what should we do?
        
    <center><img src="../../images/ML/SVM3.png" width="300"/></center>
    
    We normalize $w$ to find the unit vector $\frac{w}{\lVert w \rVert}$, and we also have $A=x^{(i)}$. Because $AA'\parallel \overrightarrow{w}$, we can find $A'$ by:
    
    $$\begin{equation}
    A'=x^{(i)}-\gamma^{(i)}\frac{w}{\lVert w \rVert}
    \end{equation}$$
    
    and because $A'$ is on the decision boundary $w^Tx+b=0$, we get
    
    $$\begin{align}
    &w^TA'+b=0 \\
    \Longrightarrow\ &w^Tx^{(i)}+b=w^T\frac{w}{\lVert w \rVert}\gamma^{(i)} \ \ \ \ \ \ \ \ \ \bigg(w^T\frac{w}{\lVert w \rVert}=\frac{\lVert w \rVert^2}{\lVert w \rVert}\bigg) \\
    \Longrightarrow\ &\gamma^{(i)}=\bigg(\frac{w}{\lVert w \rVert}\bigg)^Tx^{(i)}+\frac{b}{\lVert w \rVert}
    \end{align}$$
    
    and if we generalize it with both classes of $y^{(i)}$:
    
    $$\begin{equation}
    \gamma^{(i)}=y^{(i)}\Bigg(\bigg(\frac{w}{\lVert w \rVert}\bigg)^Tx^{(i)}+\frac{b}{\lVert w \rVert}\Bigg)
    \end{equation}$$
    
&emsp;<a name="lagrange"></a>
## Optimization: Lagrange Duality

- **Constrained optimization problem**
    
    $$\begin{equation}
    \mathop{\min}_ {w} f(w)\ \ \text{s.t.}\ h_i(w)=0\ \ \forall i\in\{1,...,m\}
    \end{equation}$$
    
    <u>Interpretation</u>: Minimize a function $f(w)$ on the set $\\{w\ \|\ h_i(w)=0\ \forall i\in\\{1,...,m\\}\\}$ where $w$ satisfies the equality constraints.
    
- **Lagrangian**

    $$\begin{equation}
    \mathcal{L}(w,\beta)=f(w)+\sum_{i=1}^{m}{\beta_ih_i(w)}
    \end{equation}$$
    
    where $\beta_i=$ Lagrange multipliers, and then we solve it by $\frac{\partial{\mathcal{L}}}{\partial{w_i}}=0$ and $\frac{\partial{\mathcal{L}}}{\partial{\beta_i}}=0$
    
- **Generalized constrained optimization problem**

    $$\begin{align}
    \mathop{\min}_ {w} f(w)\ \ \text{s.t.}\ h_i(w)=0\ \ &\forall i\in\{1,...,m\} \\
    g_i(w)\leq 0\ \ &\forall i\in\{1,...,n\}
    \end{align}$$
    
    <u>Interpretation</u>: Add an inequality constraint to the original optimization problem.
    
- **Generalized Lagrangian**

    $$\begin{equation}
    \mathcal{L}(w,\alpha,\beta)=f(w)+\sum_{i=1}^{m}{\beta_ih_i(w)}+\sum_{i=1}^{n}{\alpha_ig_i(w)}
    \end{equation}$$
    
- **Primal optimization problem**

    $$\begin{equation}
    p^* =\mathop{\min}_ {w} \theta_{\mathcal{P}}(w)=\mathop{\min}_ {w} \mathop{\max}_ {\alpha,\beta:\alpha_i\geq0} \mathcal{L}(w,\alpha,\beta)
    \end{equation}$$
    
    <u>Interpretation</u>: Under the 2 primal constraints above, the maximum of our generalized lagrangian (labeled as $\theta_{\mathcal{P}}(w)$) is basically just $f(w)$ as long as $\alpha_i\geq0\ \forall i\in\\{1,...,m\\}$:
    
    $$\begin{align}
    &\sum_{i=1}^{m}{\beta_ih_i(w)}\longrightarrow\sum_{i=1}^{m}{\beta_i\cdot0}\longrightarrow0 \\
    &\sum_{i=1}^{m}{\alpha_ig_i(w)}\xrightarrow{\alpha\geq0,g(w)\leq0}\sum_{i=1}^{m}{(+0\cdot-0)}\longrightarrow0
    \end{align}$$
    
    Therefore, this is just another way to write our generalized optimization problem.
    
- **Dual optimization problem**

    $$\begin{equation}
    d^* =\mathop{\max}_ {\alpha,\beta:\alpha_i\geq0} \theta_{\mathcal{D}}(\alpha,\beta)=\mathop{\max}_ {\alpha,\beta:\alpha_i\geq0} \mathop{\min}_ {w} \mathcal{L}(w,\alpha,\beta)
    \end{equation}$$

    <u>Interpretation</u>: This is basically the same problem as primal except that $\mathop{\max}$ and $\mathop{\min}$ are exchanged. However, their values are not necessarily equal. Instead, they follow the following relationship:
    
    $$\begin{equation}
    d^* \leq p^*
    \end{equation}$$
    
    The intuition is simple. Suppose we have a function $f(x,y)$, then:
    
    $$\begin{align}
    \mathop{\min}_ {w} f(x,w)\leq f(x,y)\leq \mathop{\max}_ {v} f(v,y) \\
    \mathop{\min}_ {u} f(u,y)\leq f(x,y)\leq \mathop{\max}_ {t} f(x,t)
    \end{align}$$
    
    This definitely holds for all functions in the world. Therefore, the following also holds:
    
    $$\begin{equation}
    \mathop{\max}_ {x} \big(\mathop{\min}_ {w} f(x,w)\big)\leq \mathop{\min}_ {y} \big(\mathop{\max}_ {v} f(v,y)\big)
    \end{equation}$$
    
    which is basically saying that "$\mathop{\max}\mathop{\min}\leq\mathop{\min}\mathop{\max}$" for all multivariate functions, including our Lagrangian.
    
- <a name="KKT"></a>**Karush-Kuhn-Tucker Conditions (KKT)**

    - Under the above assumptions, there must exist $w^*,\alpha^ *,\beta^ *$ so that 
    
        - $w^*$ is the solution to the primal problem
        - $\alpha^ *,\beta^ *$ are the solution to the dual problem
        - $p^* =d^* =\mathcal{L}(w^* ,\alpha^ * ,\beta^ * )$
        
    - KKT Conditions: $w^*,\alpha^ *,\beta^ *$ must satisfy:
    
        $$\begin{align}
        \frac{\partial}{\partial w_i}\mathcal{L}(w^*,\alpha^*,\beta^* )&=0\ \ i=1,\cdots,n \\
        \frac{\partial}{\partial \beta_i}\mathcal{L}(w^*,\alpha^*,\beta^* )&=0\ \ i=1,\cdots,l \\
        \alpha_i^* g_i(w^* )&=0\ \ i=1,\cdots,k \\
        g_i(w^* )&\leq0\ \ i=1,\cdots,k \\
        \alpha_i^* &\geq0\ \ i=1,\cdots,k
        \end{align}$$
    