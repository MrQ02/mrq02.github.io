---
layout: post
title: "Convolutional Neural Networks"
date: 2019-12-01 22:29:53 +0900
permalink: /DL/CNN/
header-includes:
- \usepackage{amsmath}
- \usepackage{mathtools}
---

Roadmap:
- Basics of CNN
    - [Intuition of CNN](#cnn)
    - [Edge Detection & Filter](#f)
    - [Padding](#p)
    - [Stride](#s)
    - [General Formula of Convolution](#formula)
    - [CNN Layers](#layers)
        - Convolution
        - [Pooling](#pool)
            - Max Pooling
            - Average Pooling
            - Stochastic Pooling
        - [Fully Connected](#fc)
- Widely Used CNNs
    - [LeNet-5](#lenet)
    - [AlexNet](#alexnet)
    - [VGG](#vgg)
    - [ResNets](#res)
    - [Conv1D](#conv1d)
    - [Inception](#inception) (the most powerful CNN as far as I know)
- [Object Detection](#od)
    - [Object Localization]
    - [Landmark Detection]
    - [Sliding Windows]
    - [Bounding Box]
    - [Intersection over Union]
    - [YOLO (You Only Look Once)]
    - [R-CNN]
- [Face Recognition](#fr)
    - [Face Verification vs Face Recognition]
    - [One Shot Learning]
    - [Siamese Network]
    - [Triplet Loss]
    - [Binary Classification]
    - [Neural Style Transfer]

&emsp;
## Basics of CNN

- <a name="cnn"></a>**Intuition of CNN**
    
    <center><img src="../../images/DL/cnn.gif" width="500"/></center>
    <br/>
    - CNN is mostly used in Computer Vision (image classification, object detection, neural style transfer, etc.)  
    
    - **Input**: images $\rightarrow$ volume of numerical values in the shape of **width $\times$ height $\times$ color-scale** (color-scale=3 $\rightarrow$ RGB; color-scale=1 $\rightarrow$ BW)  
    
        In the gif above, the input shape is $5\times5\times3$, meaning that the image is colored and the image size $5\times5$. The "$7\times7\times3$" results from **padding**, which will be discussed below.
    
    - **Convolution**: 
        1. For each color layer of the input image, we apply a 2d **filter** that **scans** through the layer in order.
        2. For each block that the filter scans, we **multiply** the corresponding filter value and the cell value, and we **sum** them up.
        3. We **sum** up the output values from all layers of the filter (and add a bias value to it) and **output** this value to the corresponding output cell. 
        4. (If there are multiple filters, ) After the first filter finishes scanning, the next filter starts scanning and outputs into a new layer.  
    <br/>
    - In the gif above, 
        1. Apply 2 filters of the shape $3\times3\times3$.
        2. 1st filter - 1st layer - 1st block: 
        
            $$\begin{equation}
            0+0+0+0+0+0+0+(1\times-1)+0=-1
            \end{equation}$$
            
            1st filter - 2nd layer - 1st block:
            
            $$\begin{equation}
            0+0+0+0+(2\times-1)+(1\times1)+0+(2\times1)+0=1
            \end{equation}$$
            
            1st filter - 3rd layer - 1st block:
            
            $$\begin{equation}
            0+0+0+0+(2\times1)+0+0+(1\times-1)+0=1
            \end{equation}$$
            
        3. Sum up + bias $\rightarrow$ 1st cell of 1st output layer
            
            $$\begin{equation}
            -1+1+1+1=2
            \end{equation}$$
    
        4. Repeat till we finish scanning  
<br/>
- <a name="f"></a>**Edge Detection & Filter**

    - Sample filters
    
        <center><img src="../../images/DL/edgedetect.png" width="500"/></center>
        
        - Gray Scale: 1 = lighter, 0 = gray, -1 = darker  
    <br/>
    - Notice that we don't really need to define any filter values. Instead, we are supposed to train the filter values.  
    All the convolution operations above are just the same as the operations in ANN. Filters here correspond to $W$ in ANN.  
    
- <a name="p"></a>**Padding**

    - Problem: corner cells & edge cells are detected much fewer times than the middle cells $\rightarrow$ info loss of corner & edge
    
    - Solution: pad the edges of the image with "0" cells (as shown in the gif above)
    
- <a name="s"></a>**Stride**: the step size the filter takes ($s=2$ in the gif above)

- <a name="formula"></a>**General Formula of Convolution**: 

    $$\begin{equation}
    \text{Output Size}=\left\lfloor\frac{n+2p-f}{s}+1\right\rfloor\times\left\lfloor\frac{n+2p-f}{s}+1\right\rfloor
    \end{equation}$$
    
    - $n\times n$: image size
    - $f\times f$: filter size
    - $p$: padding
    - $s$: stride
    - Floor: ignore the computation when the filter sweeps the region outside the image matrix  
<br/>
- <a name="layers"></a>**CNN Layers**:

    - **Convolution** (CONV): as described above
    
    - <a name="pool"></a>**Pooling** (POOL): to reduce #params & computations (most common pooling size = $2\times2$)
    
        - Max Pooling
        
            <center><img src="../../images/DL/maxpool.png" height="200"/></center>
            
            1. Divide the matrix evenly into regions
            2. Take the max value in that region as output value  
            <br/>
        - Average Pooling
        
            <center><img src="../../images/DL/avgpool.png" height="190"/></center>
            
            1. Divide the matrix evenly into regions
            2. Take the average value of the cells in that region as output value  
            <br/>
        - Stochastic Pooling
        
            <center><img src="../../images/DL/stochasticpool.png" height="200"/></center>
            
            1. Divide the matrix evenly into regions
            2. Normalize each cell based on the regional sum:
            
                $$\begin{equation}
                p_i=\frac{a_i}{\sum_{k\in R_j}{a_k}}
                \end{equation}$$
                
            3. Take a random cell based on multinomial distribution as output value  
        <br/>
    - <a name="fc"></a>**Fully Connected** (FC): to flatten the 2D/3D matrices into a single vector (each neuron is connected with all input values)
    
        <center><img src="../../images/DL/fullyconnected.png" width="300"/></center>

&emsp;
## Widely Used CNNs

<a name="lenet"></a>**LeNet-5**: LeNet-5 Digit Recognizer
        
<center><img src="../../images/DL/cnneg.png"/></center>  

|  Layer  |  Shape  | Total Size | #params |
| :-----: | :-----: | :--------: | :-----: |
| INPUT | 32 x 32 x 3 | 3072 | 0 |
| CONV1 (Layer 1) | 28 x 28 x 6 | 4704 | 156 |
| POOL1 (Layer 1) | 14 x 14 x 6 | 1176 | 0 |
| CONV2 (Layer 2) | 10 x 10 x 16 | 1600 | 416 |
| POOL2 (Layer 2) | 5 x 5 x 16 | 400 | 0 |
| FC3 (Layer 3) | 120 x 1 | 120 | 48001 |
| FC4 (Layer 4) | 84 x 1 | 84 | 10081 |
| Softmax | 10 x 1 | 10 | 841 |

- Calculation of #params for CONV: $(f\times f+1)\times n_f$
    - $f$: filter size
    - $+1$: bias
    - $n_f$: #filter

Because the NN graph took too long to make, most of the NN graphs in this session are quoted from Andrew Ng's <a href="https://www.coursera.org/specializations/deep-learning" target="_blank">Deep Learning</a> Course on Coursera.    
<br/>
<a name="alexnet"></a>**AlexNet**: winner of 2012 ImageNet Large Scale Visual Recognition Challenge  

<center><img src="../../images/DL/alexnet.png"/></center>  

<br/>
<a name="vgg"></a>**VGG**: made by Visual Geometry Group from Oxford  

<center><img src="../../images/DL/vgg.png"/></center>  

<br/>
<a name="res"></a>**ResNets**  
<br/>
<a name="conv1d"></a>**Conv1D**  
<br/>
<a name="inception"></a>**Inception**  
<br/>