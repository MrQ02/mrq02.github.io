<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-01-24T20:09:50+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Mr.Q’s HUB</title><entry><title type="html">Differential Equations</title><link href="http://localhost:4000/math/diffeq/" rel="alternate" type="text/html" title="Differential Equations" /><published>2020-04-25T11:47:53+08:00</published><updated>2020-04-25T11:47:53+08:00</updated><id>http://localhost:4000/math/math-diffeq</id><content type="html" xml:base="http://localhost:4000/math/diffeq/">&lt;p&gt;Roadmap:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#1oode&quot;&gt;Linear 1st-Order ODE&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#2oode&quot;&gt;Linear 2nd-Order ODE&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt; &lt;a name=&quot;1oode&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;linear-1st-order-ode&quot;&gt;Linear 1st-Order ODE&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Problem&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  y'+p(x)y=q(x)
  \end{equation}&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Solution&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  y=Ce^{-\int{p(x)dx}}+e^{-\int{p(x)dx}}\times\int{q(x)e^{\int{p(x)dx}}}dx
  \end{equation}&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Derivation&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Solve for $y_h$:&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
 y_h'+p(x)y_h&amp;=0 \\
 \int{\frac{dy_h}{y_h}}&amp;=\int{-p(x)dx} \\
 y_h&amp;=e^{-\int{p(x)dx}}
 \end{align} %]]&gt;&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Let $u(x)$ be an integrating factor. Multiply this on both sides:&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
 u(x)y'+u(x)p(x)y=u(x)q(x)
 \end{equation}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Recall product rule $(fg)’=f’g+fg’$. Notice:&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
 f=y &amp;\Rightarrow f'=y'\\
 g=u(x) &amp;\Rightarrow g'=u(x)p(x) \\
 (fg)'&amp;=u(x)q(x)
 \end{align} %]]&gt;&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Solve for $u(x)$:&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
 u'(x)&amp;=u(x)p(x) \\
 \int{\frac{du}{u}}&amp;=\int{p(x)dx} \\
 u(x)&amp;=e^{\int{p(x)dx}}
 \end{align} %]]&gt;&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Solve for $y_g$:&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
 \big(u(x)y_g\big)'&amp;=u(x)q(x) \\
 u(x)y_g&amp;=\int{u(x)q(x)dx} \\
 y_g&amp;=\frac{\int{u(x)q(x)dx}}{u(x)} \\
 y_g&amp;=\frac{\int{e^{\int{p(x)dx}}q(x)dx}}{e^{\int{p(x)dx}}}
 \end{align} %]]&gt;&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Roadmap: Linear 1st-Order ODE Linear 2nd-Order ODE</summary></entry><entry><title type="html">Probability</title><link href="http://localhost:4000/PS/prob/" rel="alternate" type="text/html" title="Probability" /><published>2020-04-25T11:47:53+08:00</published><updated>2020-04-25T11:47:53+08:00</updated><id>http://localhost:4000/PS/PS-prob</id><content type="html" xml:base="http://localhost:4000/PS/prob/">&lt;p&gt;Roadmap:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Basics
    &lt;ul&gt;
      &lt;li&gt;Sampling Table&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt; &lt;a name=&quot;basics&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;basics&quot;&gt;Basics&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a name=&quot;prob&quot;&gt;&lt;/a&gt;&lt;strong&gt;Sampling Table&lt;/strong&gt;: #diff ways to take a sample of $k$ out of a population $n$&lt;/p&gt;

    &lt;table&gt;
      &lt;thead&gt;
        &lt;tr&gt;
          &lt;th style=&quot;text-align: center&quot;&gt; &lt;/th&gt;
          &lt;th style=&quot;text-align: center&quot;&gt;Order&lt;/th&gt;
          &lt;th style=&quot;text-align: center&quot;&gt;No Order&lt;/th&gt;
        &lt;/tr&gt;
      &lt;/thead&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;Replacement&lt;/td&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;$n^k$&lt;/td&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;\begin{pmatrix}n+k-1 \\ k \end{pmatrix}=\frac{(n+k-1)!}{k!(n-1)!}&lt;/script&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;No replacement&lt;/td&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;\frac{n!}{(n-k)!}&lt;/script&gt;&lt;/td&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;\begin{pmatrix}n \\ k \end{pmatrix}=\frac{n!}{k!(n-k)!}&lt;/script&gt;&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Examples:&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;Draw 1 card out of 5 cards and put it back for 2 times with order: $5^2=25$&lt;/li&gt;
          &lt;li&gt;Draw 1 card out of 5 cards and put it back for 2 times with no order: &lt;script type=&quot;math/tex&quot;&gt;\begin{pmatrix}5+2-1 \\ 2\end{pmatrix}=15&lt;/script&gt;&lt;/li&gt;
          &lt;li&gt;Draw 2 cards out of 5 cards at once with order: $\frac{5!}{(5-2)!}=20$&lt;/li&gt;
          &lt;li&gt;Draw 2 cards out of 5 cards at once with no order: &lt;script type=&quot;math/tex&quot;&gt;\begin{pmatrix}5 \\ 2 \end{pmatrix}=10&lt;/script&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Roadmap: Basics Sampling Table</summary></entry><entry><title type="html">Generalized Linear Models</title><link href="http://localhost:4000/ML/GLM/" rel="alternate" type="text/html" title="Generalized Linear Models" /><published>2019-12-01T21:29:53+08:00</published><updated>2019-12-01T21:29:53+08:00</updated><id>http://localhost:4000/ML/ML-GLM</id><content type="html" xml:base="http://localhost:4000/ML/GLM/">&lt;p&gt;Roadmap:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#bernoulli&quot;&gt;Bernoulli Distribution&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#gaussian&quot;&gt;Gaussian Distribution&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#poisson&quot;&gt;Poisson Distribution&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#gamma&quot;&gt;Gamma Distribution&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#beta&quot;&gt;Beta Distribution&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#dirichlet&quot;&gt;Dirichlet Distribution&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#construct&quot;&gt;Method of Constructing GLMs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#softmax&quot;&gt;Softmax Regression&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt; &lt;/p&gt;
&lt;h3 id=&quot;glm&quot;&gt;GLM&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;What are &lt;strong&gt;GLM&lt;/strong&gt;s?&lt;/p&gt;

    &lt;p&gt;Remember the two models we had in the last post?&lt;br /&gt;
  Regression:      $p(y|x,w)\sim N(\mu,\sigma^2)$&lt;br /&gt;
  Classification:   $p(y|x,w)\sim \text{Bernoulli}(\phi)$&lt;/p&gt;

    &lt;p&gt;They belong to GLM, a collection of models that can be applied to Supervised Learning problems. We will show more examples of GLMs in this markdown.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Exponential Family&lt;/strong&gt;&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  p(y,\eta)=b(y)\cdot e^{\eta^TT(y)-a(\eta)}
  \end{equation}&lt;/script&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;$\eta$: natural parameter (i.e. canonical parameter)&lt;/p&gt;

        &lt;p&gt; different $\eta \rightarrow$ different distributions within the family&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$T(y)$: sufficient statistic (usually, $T(y)=y$)&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$a(\eta)$: log partition function&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$e^{-a(\eta)}$: normalization constant (to ensure that $\int{p(y,\eta)dy}=1$)&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$T,a,b$: fixed choice that defines a family of distributions parametrized by $\eta$&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;a name=&quot;bernoulli&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Bernoulli Distribution&lt;/strong&gt; (Classification)&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
  p(y|\phi)&amp;=\phi^y(1-\phi)^{1-y} \\
  &amp;=e^{y\log{\phi}+(1-y)\log{(1-\phi)}} \\
  &amp;=e^{y\log{\frac{\phi}{1-\phi}}+\log{(1-\phi)}} \\
  \end{align} %]]&gt;&lt;/script&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;$\eta=\log{\frac{\phi}{1-\phi}}\Leftrightarrow \phi=\frac{1}{1+e^{-\eta}}$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$T(y)=y$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$a(\eta)=\log{(1+e^\eta)}$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$b(y)=1$&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;a name=&quot;gaussian&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Gaussian Distribution&lt;/strong&gt; (Regression)&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
  p(y|\mu,\sigma^2)&amp;=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{1}{2\sigma^2}(y-\mu)^2} \\
  &amp;=\frac{1}{\sqrt{2\pi}}e^{\frac{\mu}{\sigma^2}y-\frac{1}{2\sigma^2}y^2-\frac{1}{2\sigma^2}\mu^2-\log{\sigma}}
  \end{align} %]]&gt;&lt;/script&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;$\eta=\begin{bmatrix}
    \frac{\mu}{\sigma^2} ;
    \frac{-1}{2\sigma^2}
   \end{bmatrix}$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$T(y)=\begin{bmatrix}
    y;
    y^2
   \end{bmatrix}$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$a(\eta)=\frac{1}{2\sigma^2}\mu^2-\log{\sigma}=-\frac{\eta_1^2}{4\eta_2}-\frac{1}{2}\log{(-2\eta_2)}$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$b(y)=\frac{1}{\sqrt{2\pi}}$&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;a name=&quot;poisson&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Poisson Distribution&lt;/strong&gt; (count-data)&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
  p(y|\lambda)&amp;=\frac{\lambda^ye^{-\lambda}}{y!}\\
  &amp;=\frac{1}{y!}e^{y\log{\lambda}-\lambda}
  \end{align} %]]&gt;&lt;/script&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;$\eta=\log{\lambda}$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$T(y)=y$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$a(\eta)=e^\eta$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$b(y)=\frac{1}{y!}$&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;a name=&quot;gamma&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Gamma Distribution&lt;/strong&gt; (continuous non-negative random variables)&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
  p(y|\lambda,a)&amp;=\frac{\lambda^ay^{a-1}e^{-\lambda y}}{\Gamma(a)}\\
  &amp;=\frac{y^{a-1}}{\Gamma(a)}e^{-\lambda y+a\log{\lambda}}
  \end{align} %]]&gt;&lt;/script&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;$\eta=-\lambda$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$T(y)=y$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$a(\eta)=-a\log{(-\eta)}$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$b(y)=\frac{y^{a-1}}{\Gamma(a)}$&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;a name=&quot;beta&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Beta Distribution&lt;/strong&gt; (distribution of probabilities)&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
  p(y|\alpha,\beta)&amp;=\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}y^{\alpha-1}(1-y)^{\beta-1} \\
  &amp;=\frac{(1-y)^\beta}{y(1-y)\Gamma(\beta)}e^{\alpha\log{y}- \log{\frac{\Gamma(\alpha)}{\Gamma(\alpha+\beta)}}} \\
  &amp;=\frac{y^\alpha}{y(1-y)\Gamma(\alpha)}e^{\beta\log{(1-y)}- \log{\frac{\Gamma(\beta)}{\Gamma(\alpha+\beta)}}}
  \end{align} %]]&gt;&lt;/script&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;$\eta=\alpha\ \text{or}\ \beta$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$T(y)=\log{y}\ \text{or}\ \log{(1-y)}$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$a(\eta)=\log{\frac{\Gamma(\eta)}{\Gamma(\alpha+\beta)}}$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$b(y)=\frac{(1-y)^\beta}{y(1-y)\Gamma(\beta)}\ \text{or}\ \frac{y^\alpha}{y(1-y)\Gamma(\alpha)}$&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;a name=&quot;dirichlet&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Dirichlet Distribution&lt;/strong&gt; (multivariate beta)&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
  p(y|\alpha)&amp;=\frac{\Gamma(\sum_k\alpha_k)}{\prod_k\Gamma(\alpha_k)}\prod_k{y_k^{\alpha_k-1}} \\
  &amp;=\exp{\big(\sum_k{(\alpha_k-1)\log{y_k}}-\big[\sum_k{\log{\Gamma(\alpha_k)}}-\log{\Gamma(\sum_k{\alpha_k})}\big]\big)}
  \end{align} %]]&gt;&lt;/script&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;$\eta=\alpha-1$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$T(y)=\log{y}$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$a(\eta)=\sum_k{\log{\Gamma(\alpha_k)}}-\log{\Gamma(\sum_k{\alpha_k})}$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$b(y)=1$&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;a name=&quot;construct&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;method-of-constructing-glms&quot;&gt;Method of Constructing GLMs&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;3 Assumptions&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;$y|x,w \sim \text{ExponentialFamily}(\eta)$&lt;/p&gt;

        &lt;p&gt;$y$ given $x\&amp;amp;w$ follows some exponential family distribution with natural parameter $\eta$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$h(x)=\text{E}[y|x]$&lt;/p&gt;

        &lt;p&gt;Our hypothetical model $h(x)$ should predict the expected value of $y$ given $x$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$\eta=w^Tx$&lt;/p&gt;

        &lt;p&gt;$\eta$ is linearly related to $x$&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Example 1: OLS (Ordinary Least Squares) (i.e. LinReg)&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
  h(x)&amp;=\text{E}[y\|x,w]\ \ \ \ \ \ &amp;\text{(Assumption 2)} \\
     &amp;=\mu \\
     &amp;=\eta\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ &amp;\text{(Assumption 1)} \\
     &amp;=w^Tx\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ &amp;\text{(Assumption 3)}
  \end{align} %]]&gt;&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Example 2: Logistic Regression&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
  h(x)&amp;=\text{E}[y\|x,w]\ \ \ \ \ \ &amp;\text{(Assumption 2)} \\
     &amp;=\phi \\
     &amp;=\frac{1}{1+e^{-\eta}}\ \ \ \ \ \ &amp;\text{(Assumption 1)} \\
     &amp;=\frac{1}{1+e^{-w^Tx}}\ \ \ \ \ \ &amp;\text{(Assumption 3)}
  \end{align} %]]&gt;&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Example 3: &lt;a name=&quot;softmax&quot;&gt;&lt;/a&gt;&lt;strong&gt;Softmax Regression&lt;/strong&gt;&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Softmax is a method used in &lt;strong&gt;multiclass classification&lt;/strong&gt; to select one output value $\phi_i$ of the highest probability among all the output values.&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
 \hat{y}=\begin{bmatrix}
 \phi_1 \\
 \vdots \\
 \phi_{k-1}
 \end{bmatrix}
 \end{equation}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;One-hot Encoding&lt;/strong&gt;&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
 y\in \{ 1,\cdots,k \} \Rightarrow T(y)\in \mathbb{R}^{k}
 \end{equation}&lt;/script&gt;

        &lt;p&gt;where&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
 T(1)=\begin{bmatrix}
 1 \\ 0 \\ \vdots \\ 0
 \end{bmatrix},
 T(2)=\begin{bmatrix}
 0 \\ 1 \\ \vdots \\ 0
 \end{bmatrix},\cdots,
 T(k)=\begin{bmatrix}
 0 \\ 0 \\ \vdots \\ 1
 \end{bmatrix}
 \end{equation}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Dummy Encoding&lt;/strong&gt;&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
 y\in \{ 1,\cdots,k \} \Rightarrow T(y)\in \mathbb{R}^{k-1}
 \end{equation}&lt;/script&gt;

        &lt;p&gt;where&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
 T(1)=\begin{bmatrix}
 1 \\ 0 \\ \vdots \\ 0
 \end{bmatrix},
 T(2)=\begin{bmatrix}
 0 \\ 1 \\ \vdots \\ 0
 \end{bmatrix},\cdots,
 T(k-1)=\begin{bmatrix}
 0 \\ 0 \\ \vdots \\ 1
 \end{bmatrix},
 T(k)=\begin{bmatrix}
 0 \\ 0 \\ \vdots \\ 0
 \end{bmatrix}
 \end{equation}&lt;/script&gt;

        &lt;p&gt;Why Dummy Encoding &amp;gt; One-hot Encoding? It reduces 1 entire column!&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Indicator Function&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
 \text{I}\{ \text{True} \}=1,\ \text{I}\{ \text{False} \}=0
 \end{equation}&lt;/script&gt;

        &lt;p&gt;Therefore,&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
 T(y)_i =\text{I}\{ y=i \}
 \end{equation}&lt;/script&gt;

        &lt;p&gt;Therefore,&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
 \text{E}[T(y)_i] =P(y=i)=\phi_i
 \end{equation}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Exponential Family form&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
 p(y|\phi)&amp;=\prod_{i=1}^{k}{\phi_i^{\text{I}\{ y=i \}}} \\
 &amp;=\prod_{i=1}^{k-1}{\phi_i^{T(y)_i}} \cdot \phi_k^{1-\sum_{i=1}^{k-1}{T(y)_i}} \\
 &amp;=\exp{\big(\sum_{i=1}^{k-1}{T(y)_i\log{(\phi_i)}-\sum_{i=1}^{k-1}{T(y)_i}\log{(\phi_k)}}+\log{(\phi_k)}\big)} \\
 &amp;=\exp{\big(\sum_{i=1}^{k-1}{T(y)_i\log{\big(\frac{\phi_i}{\phi_k}\big)}+\log{(\phi_k)}\big)}} \\
 \end{align} %]]&gt;&lt;/script&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;$\eta=\begin{bmatrix}\log{\big(\frac{\phi_1}{\phi_k}\big)}\ ;\ \cdots\ ;\ \log{\big(\frac{\phi_{k-1}}{\phi_k}\big)}\end{bmatrix}$&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;$T(y)=\begin{bmatrix}T(y)_1\ ;\ \cdots\ ;\ T(y)_k-1\end{bmatrix}$&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;$a(\eta)=-\log{(\phi_k)}$&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;$b(y)=1$&lt;br /&gt;
  &lt;/p&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Softmax Function&lt;/strong&gt; (derived from $\eta_i=\log{\big(\frac{\phi_i}{\phi_k}\big)}$)&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
 \phi_i=\frac{e^{\eta_i}}{\sum_{j=1}^k{e^{\eta_j}}}
 \end{equation}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Probabilistic Interpretation of Softmax Regression&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
 p(y=i|x,w)=\frac{e^{w_i^Tx}}{\sum_{j=1}^k{e^{w_i^Tx}}}
 \end{equation}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Log Likelihood&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
 l(w)&amp;=\sum_{i=1}^m{\log{p(y^{(i)}|x^{(i)},w)}} \\
 &amp;=\sum_{i=1}^m{\log{\prod_{i=1}^{k}{\Bigg(\frac{e^{w_l^Tx^{(i)}}}{\sum_{j=1}^k{e^{w_l^Tx^{(i)}}}}\Bigg)^{\text{I}\{ y^{(i)}=l \}}}}}
 \end{align} %]]&gt;&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Roadmap: Bernoulli Distribution Gaussian Distribution Poisson Distribution Gamma Distribution Beta Distribution Dirichlet Distribution Method of Constructing GLMs Softmax Regression</summary></entry><entry><title type="html">Classification</title><link href="http://localhost:4000/ML/class/" rel="alternate" type="text/html" title="Classification" /><published>2019-12-01T21:29:53+08:00</published><updated>2019-12-01T21:29:53+08:00</updated><id>http://localhost:4000/ML/ML-class</id><content type="html" xml:base="http://localhost:4000/ML/class/">&lt;p&gt;Roadmap:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#logreg&quot;&gt;Logistic Regression&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#learn&quot;&gt;Learning&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#gd&quot;&gt;Gradient Descent&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#newton&quot;&gt;Newton’s Method&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#normal&quot;&gt;Normal Equation&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#code&quot;&gt;Code Template&lt;/a&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#knn&quot;&gt;k-Nearest Neighbors&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#statsclass&quot;&gt;Statistical Setting for Classification&lt;/a&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#gda&quot;&gt;Gaussian Discriminant Analysis&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#bayes&quot;&gt;2 Types of Learning Algorithms &amp;amp; Bayes Theorem&lt;/a&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#nb&quot;&gt;Naive Bayes Classifier&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#laplace&quot;&gt;Laplace Smoothing&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt; &lt;a name=&quot;logreg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;logistic-regression&quot;&gt;Logistic Regression&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Problem Setting&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Data&lt;/strong&gt;: Observed pairs $(x,y)$, where $x\in\mathcal{X}$ &amp;amp; $y\in\mathcal{Y}$
        &lt;ul&gt;
          &lt;li&gt;$\mathcal{Y}=\{-1,+1\}\lor\{0,1\}$: binary classification&lt;/li&gt;
          &lt;li&gt;$\mathcal{Y}=\{1,…,K\}$: multiclass classification&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Goal&lt;/strong&gt;: Find a classifier $f$ that can map input $x$ to class $y$: $y=f(x):\ “x\in\mathcal{X}”\rightarrow\ “y\in\mathcal{Y}”$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Model&lt;/strong&gt;&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  \hat{y}=g(w^Tx)
  \end{equation}&lt;/script&gt;

    &lt;p&gt;$g(z)$: a function that converts $w^Tx$ to binary value&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sigmoid Function (see Deep Learning for more funcs)&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  g(z)=\sigma(z)=\frac{1}{1+e^{-z}}
  \end{equation}&lt;/script&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Derivative (you will know why we need this in Deep Learning)&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
  g'(z)&amp;=\frac{d}{dz}\frac{1}{1+e^{-z}} \\
  &amp;=\frac{e^{-z}(+1-1)}{(1+e^{-z})^2} \\
  &amp;=g(z)(1-g(z))
  \end{align} %]]&gt;&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Cost Function&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;single training example (derivation later)&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
 \mathcal{L}(\hat{y},y)=-(y\log{\hat{y}}+(1-y)\log{(1-\hat{y})})
 \end{equation}&lt;/script&gt;

        &lt;p&gt;If $y=1\rightarrow\mathcal{L}(\hat{y},y)=-\log{\hat{y}}\rightarrow$ want “$\mathcal{L}\downarrow\leftrightarrow\hat{y}\uparrow$”$\rightarrow\hat{y}=1$ &lt;br /&gt;
 If $y=0\rightarrow\mathcal{L}(\hat{y},y)=-\log{(1-\hat{y})}\rightarrow$ want “$\mathcal{L}\downarrow\leftrightarrow\hat{y}\downarrow$”$\rightarrow\hat{y}=0$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;entire training set&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
 \mathcal{J}(w)=\frac{1}{m}\sum_{i=1}^{m}\mathcal{L}(\hat{y}^{(i)},y^{(i)})=\text{mean}(\mathcal{L})
 \end{equation}&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Probabilistic Interpretation&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Assumptions&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
 P(y=1|x,w)&amp;=\hat{y} \\
 P(y=0|x,w)&amp;=1-\hat{y}
 \end{align} %]]&gt;&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Probabilistic Model of LogReg&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
 p(y|x,w)=\hat{y}^y(1-\hat{y})^{1-y}
 \end{equation}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Likelihood Function&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
 L(w)=\prod_{i=1}^{m}(\hat{y}^{(i)})^{y^{(i)}}(1-\hat{y}^{(i)})^{1-y^{(i)}}
 \end{equation}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Log Likelihood&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
 l(w)&amp;=\sum_{i=1}^{m}(y^{(i)}\log{\hat{y}^{(i)}}+(1-y^{(i)})\log{(1-\hat{y}^{(i)})}) \\
 l(w)&amp;=-\sum_{i=1}^{m}\mathcal{L}(\hat{y},y)
 \end{align} %]]&gt;&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;MLE&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
 \frac{\partial l(w)}{\partial w_j}&amp;=(\frac{y}{g(w^Tx)}-\frac{1-y}{1-g(w^Tx)})\frac{\partial g(w^Tx)}{\partial w_j} \\
 &amp;=(\frac{y}{g(w^Tx)}-\frac{1-y}{1-g(w^Tx)})g(w^Tx)(1-g(w^Tx))\frac{\partial(w^Tx)}{\partial w_j} \\
 &amp;=(y(1-g(w^Tx))-(1-y)g(w^Tx))x_j \\
 &amp;=(y-\hat{y})x_j
 \end{align} %]]&gt;&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Gradient Descent&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
  w_j &amp;:= w_j-\alpha\frac{\partial\mathcal{L}(w)}{\partial w_j} \\
  &amp;=w_j+\alpha(y-\hat{y})x_j
  \end{align} %]]&gt;&lt;/script&gt;

    &lt;p&gt;Why is it also called “Gradient Ascent”?&lt;br /&gt;
  $\because$ we are trying to minimize the loss function $\Leftrightarrow$ maximize the likelihood function&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt; &lt;a name=&quot;knn&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;k-nearest-neighbors&quot;&gt;k-Nearest Neighbors&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a name=&quot;knnalg&quot;&gt;&lt;/a&gt;&lt;strong&gt;Algorithm&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;For a new input $x$,&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Return the $k$ points &lt;strong&gt;closest&lt;/strong&gt; to $x$, indexed as $x_{i_1},…,x_{i_k}$.&lt;/li&gt;
      &lt;li&gt;Return the majority votes of $y_{i_1},…,y_{i_k}$.&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Distances&lt;/strong&gt; (how to measure “closest”)&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Euclidean distance&lt;/strong&gt;: default measurement&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  \|u-v\|_ 2=\Big(\sum_{i=1}^n(u_i-v_i)^2\Big)^{\frac{1}{2}}
  \end{equation}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;$l_p$&lt;/strong&gt;: variation on Euclidean&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  \|u-v\|_ p=\Big(\sum_{i=1}^n|u_i-v_i|^p\Big)^{\frac{1}{p}}\ \ \ |\ p\in[1,\infty]
  \end{equation}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Edit distance&lt;/strong&gt;: for strings&lt;/p&gt;

        &lt;center&gt;#modifications required to transform one string to the other&lt;/center&gt;
        &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Correlation distance&lt;/strong&gt;: for signals&lt;/p&gt;

        &lt;center&gt;how correlated 2 vectors are for signal detection&lt;/center&gt;
        &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;$k$&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Smaller $k$ $\Rightarrow$ smaller training error but could lead to overfitting&lt;/li&gt;
      &lt;li&gt;Larger $k$ $\Rightarrow$ more stable predictions due to voting&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Statistical Setting for Classification&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Performance&lt;/strong&gt;&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;Prediction accuracy: $P(f(x)=y)$&lt;/li&gt;
          &lt;li&gt;Prediction error: $P(f(x)\neq y)$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Key Assumption for Supervised Learning&lt;/strong&gt;&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  (x_i,y_i)\sim\mathcal{P}\ \ \ |\ \ \ i=1,\cdots,n
  \end{equation}&lt;/script&gt;

        &lt;ul&gt;
          &lt;li&gt;i.i.d. (independent &amp;amp; identically distributed)&lt;/li&gt;
          &lt;li&gt;We assume that the future should look like the past.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt; &lt;a name=&quot;gda&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;gaussian-discriminant-analysis&quot;&gt;Gaussian Discriminant Analysis&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a name=&quot;bayes&quot;&gt;&lt;/a&gt;Learning Algorithms&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Discriminative Learning Algorithms&lt;/li&gt;
    &lt;/ul&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  \text{model }p(y|x)\text{ directly}\ \ \ (X \Rightarrow Y)
  \end{equation}&lt;/script&gt;

    &lt;ul&gt;
      &lt;li&gt;Generative Learning Algorithms&lt;/li&gt;
    &lt;/ul&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{equation}
  \text{model }p(x|y)\ \&amp;\ p(y)\Rightarrow\text{ use Bayes Theorem to get }p(y|x) 
  \end{equation} %]]&gt;&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Bayes Theorem&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  p(y|x)=\frac{p(x|y)p(y)}{p(x)}
  \end{equation}&lt;/script&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Prior&lt;/strong&gt;:   $p(y)$&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Posterior&lt;/strong&gt;: $p(y|x)$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Simplification:&lt;/p&gt;

        &lt;p&gt;$\because$ we are trying to find the output $y$ with the highest probability given $x$&lt;br /&gt;
  $\therefore$ we can simplify Bayes Theorem for our purpose:&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
  \mathop{\arg\max}_ {y}{p(y|x)}&amp;=\mathop{\arg\max}_ {y}{\frac{p(x|y)p(y)}{p(x)}} \\
  &amp;=\mathop{\arg\max}_ {y}{p(x|y)p(y)}
  \end{align} %]]&gt;&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;Bayes Theorem = the core of Generative Learning Algorithms&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Assumption: Multivariate Gaussian Distribution&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  p(x|\mu,\Sigma)=\frac{1}{(2\pi)^{\frac{n}{2}}|\Sigma|^{\frac{1}{2}}}e^{\big(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)\big)}
  \end{equation}&lt;/script&gt;

    &lt;p&gt;It is literally the same as Gaussian Distribution but with vector parameters:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;mean vector:    $\mu\in\mathbb{R}^n$&lt;/li&gt;
      &lt;li&gt;covariance matrix: $\Sigma\in\mathbb{R}^{n\times n}$&lt;br /&gt;
   &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;As a reminder and a comparison, here is the univariate version:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  p(x|\mu,\sigma)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}
  \end{equation}&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Model&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
  y&amp;\sim \text{Bernoulli}{(\phi)} \\
  x|y=0&amp;\sim N(\mu_0,\Sigma) \\
  x|y=1&amp;\sim N(\mu_1,\Sigma) \\
  \end{align} %]]&gt;&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Probabilistic Interpretation&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
  p(y)&amp;=\phi^y(1-\phi)^{1-y} \\
  p(x|y=0)&amp;=\frac{1}{(2\pi)^{\frac{n}{2}}|\Sigma|^{\frac{1}{2}}}e^{\big(-\frac{1}{2}(x-\mu_0)^T\Sigma^{-1}(x-\mu_0)\big)} \\
  p(x|y=1)&amp;=\frac{1}{(2\pi)^{\frac{n}{2}}|\Sigma|^{\frac{1}{2}}}e^{\big(-\frac{1}{2}(x-\mu_1)^T\Sigma^{-1}(x-\mu_1)\big)}
  \end{align} %]]&gt;&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;log likelihood&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  l(\phi,\mu_0,\mu_1,\Sigma)=\log{\prod_{i=1}^{m}{p(x^{(i)}|y^{(i)};\mu_0,\mu_1,\Sigma)p(y^{(i)};\phi)}}
  \end{equation}&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;MLE&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
  \phi &amp;= \frac{1}{m}\sum_{i=1}^m{\text{I}\{ y^{(i)}=l \}} \\
  \mu_0 &amp;= \frac{\sum_{i=1}^m{\text{I}\{ y^{(i)}=0 \}x^{(i)}}}{\sum_{i=1}^m{\text{I}\{ y^{(i)}=0 \}}} \\
  \mu_1 &amp;= \frac{\sum_{i=1}^m{\text{I}\{ y^{(i)}=1 \}x^{(i)}}}{\sum_{i=1}^m{\text{I}\{ y^{(i)}=1 \}}} \\
  \Sigma &amp;= \frac{1}{m}\sum_{i=1}^m{(x^{(i)}-\mu_{y^{(i)}})(x^{(i)}-\mu_{y^{(i)}})^T}
  \end{align} %]]&gt;&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;GDA vs LogReg&lt;/p&gt;
    &lt;ol&gt;
      &lt;li&gt;GDA
        &lt;ul&gt;
          &lt;li&gt;makes &lt;strong&gt;stronger&lt;/strong&gt; modeling assumptions about data&lt;/li&gt;
          &lt;li&gt;data efficient when assumptions (Gaussian distributions) are approximately correct&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;LogReg
        &lt;ul&gt;
          &lt;li&gt;makes &lt;strong&gt;weaker&lt;/strong&gt; modeling assumptions about data&lt;/li&gt;
          &lt;li&gt;data efficient when assumptions (Gaussian distributions) are not necessarily correct (e.g. $x|y\sim \text{Poisson}(\lambda_1)$ instead of $N(\mu_0,\Sigma)$)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt; &lt;a name=&quot;nb&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;naive-bayes-classifier&quot;&gt;Naive Bayes Classifier&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;GDA vs NB&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;GDA: $x$ = continuous, real-valued vectors&lt;/li&gt;
      &lt;li&gt;NB:   $x$ = discrete-valued vectors (e.g. text classification)&lt;br /&gt;
   &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Text Encoding (more in DL/RNN)&lt;/p&gt;

    &lt;p&gt;We encode a text sentence into a vector of the same length as our &lt;strong&gt;dictionary&lt;/strong&gt; (like a Python dictionary with vocabulary and their indices as key-value pairs):&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  x=\begin{bmatrix}
  0 \\ 0 \\ \vdots \\ 1 \\ \vdots \\ 1 \\ 1 \\ \vdots \\ 0
  \end{bmatrix}
  \begin{matrix}
  \text{a} \\ \text{abandon} \\ \vdots \\ \text{pewdiepie} \\ \vdots \\ \text{subscribe} \\ \text{to} \\ \vdots \\ \text{zuck}
  \end{matrix}
  \end{equation}&lt;/script&gt;

    &lt;p&gt;The original sentence was “Subscribe to Pewdiepie!”, and this text encoding method uses lowercases, throws punctuations and ignores the order of the sentence. This is convenient in some cases (e.g. spam email classification) but awful in the other cases (e.g. news/report-writer bots)&lt;/p&gt;

    &lt;p&gt;Notice that $x\in \{0,1\}^{\text{len(dict)}}$. Why notice this? Because we now have $2^\text{len(dict)}$ possible outcomes for $x$. When we have a dictionary of over 20000 words, we have a $(2^{20000}-1)$-dimensional parameter vector. Have fun with that, laptop.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Assumption: Conditional Independence&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  p(x_i|y)=p(x_i|y,x_j)\ \ \ \forall j\neq i
  \end{equation}&lt;/script&gt;

    &lt;p&gt;meaning: Given $y$ as the condition, $x_i$ is independent of $x_j$.&lt;/p&gt;

    &lt;p&gt;In the case of spam email classification, if we know that the email is spam, then whether or not “pewdiepie” is in the sentence does not change our belief of whether or not “subscribe” is in the sentence.&lt;/p&gt;

    &lt;p&gt;Therefore, we can simplify our $p(x|y)$ into:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  p(x_1,...,x_{\text{len(dict)}}|y)=\prod_{i=1}^{n}{p(x_i|y)}
  \end{equation}&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Model&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
  \phi_{i|y=1}&amp;=p(x_i=1|y=1) \\
  \phi_{i|y=0}&amp;=p(x_i=1|y=0) \\
  \phi_y&amp;=p(y=1)
  \end{align} %]]&gt;&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Joint Likelihood&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  \mathcal{L}(\phi_y,\phi_{i|y=0},\phi_{i|y=1})=\prod_{i=1}^{m}{p(x^{(i)},y^{(i)})}
  \end{equation}&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;MLE&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
  \phi_{j|y=1}&amp;=\frac{\sum_{i=1}^m{I\{x_j^{(i)}=1\land y^{(i)}=1\}}}{\sum_{i=1}^m{I\{y^{(i)}=1\}}} \\
  \phi_{j|y=0}&amp;=\frac{\sum_{i=1}^m{I\{x_j^{(i)}=1\land y^{(i)}=0\}}}{\sum_{i=1}^m{I\{y^{(i)}=0\}}} \\
  \phi_y&amp;=\frac{\sum_{i=1}^m{I\{y^{(i)}=1\}}}{m}
  \end{align} %]]&gt;&lt;/script&gt;

    &lt;p&gt;Quite intuitive. For example, $\phi_{j|y=0}$ = the fraction of non-spam emails with the word $j$ in it.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Prediction&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
  p(y=1|x_\text{new})&amp;=\frac{p(x_\text{new}|y=1)p(y=1)}{p(x_\text{new})} \\
  &amp;=\frac{\prod_{i=1}^n{p(x_i|y=1)}\cdot p(y=1)}{\prod_{i=1}^n{p(x_i|y=1)}\cdot p(y=1)+\prod_{i=1}^n{p(x_i|y=0)}\cdot p(y=0)}
  \end{align} %]]&gt;&lt;/script&gt;

    &lt;p&gt;Again, the formula is tedious but very intuitive. The $y$ with the higher posterior probability will be chosen as the final prediction.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Apply NB in GDA cases?&lt;/p&gt;

    &lt;p&gt;Discretize: Just cut the continuous, real-valued $x$ into small intervals and label them with a discrete-valued scale.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;a name=&quot;laplace&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;laplace-smoothing&quot;&gt;&lt;strong&gt;Laplace Smoothing&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;u&gt;Problem&lt;/u&gt;: What if there is a new word “mrbeast” in the email for prediction that our NB classifier has never learnt ever since it was born?&lt;/p&gt;

&lt;p&gt;A human would look it up on a dictionary, and so would our NB classifier.&lt;/p&gt;

&lt;p&gt;Assume the word “mrbeast” is the 1234th word in the dictionary, then:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\phi_{1234|y=1}&amp;=\frac{\sum_{i=1}^m{I\{x_{1234}^{(i)}=1\land y^{(i)}=1\}}}{\sum_{i=1}^m{I\{y^{(i)}=1\}}}=0 \\
\phi_{1234|y=0}&amp;=\frac{\sum_{i=1}^m{I\{x_{1234}^{(i)}=1\land y^{(i)}=0\}}}{\sum_{i=1}^m{I\{y^{(i)}=0\}}}=0 \\
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;Yes. NB thinks that the probability of seeing this word in either spam or non-spam email is $0$, and therefore it would predict that:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
p(y=1|x_\text{new})&amp;=\frac{\prod_{i=1}^n{p(x_i|y=1)}\cdot p(y=1)}{\prod_{i=1}^n{p(x_i|y=1)}\cdot p(y=1)+\prod_{i=1}^n{p(x_i|y=0)}\cdot p(y=0)} \\
&amp;=\frac{0}{0}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;Because both numerator and denominator contains $p(x_{1234|y})=0$.&lt;/p&gt;

&lt;p&gt;In summary, during prediction, if NB has never learnt a word $j$, there will always $\phi_j=0$ ruining the entire prediction. How do we estimate the unknown?&lt;/p&gt;

&lt;p&gt;&lt;u&gt;Algorithm&lt;/u&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
\phi_j=\frac{\sum_{i=1}^m{I\{z^{(i)}=j\}}+1}{m+k}
\end{equation}&lt;/script&gt;

&lt;p&gt;where $k=\text{#features}$ if you forget.&lt;/p&gt;

&lt;p&gt;Let’s check if it still satisfies our condition:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
\sum_{j=1}^k{\phi_j}=\sum_{j=1}^k{\frac{\sum_{i=1}^m{I\{z^{(i)}=j\}}+1}{m+k}}=\frac{m+k}{m+k}=1
\end{equation}&lt;/script&gt;

&lt;p&gt;Nice. It still satisfies the basic sum rule. The estimates in NB will now become:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\phi_{j|y=1}&amp;=\frac{\sum_{i=1}^m{I\{x_{j}^{(i)}=1\land y^{(i)}=1\}}+1}{\sum_{i=1}^m{I\{y^{(i)}=1\}}+2} \\
\phi_{j|y=0}&amp;=\frac{\sum_{i=1}^m{I\{x_{j}^{(i)}=1\land y^{(i)}=0\}}+1}{\sum_{i=1}^m{I\{y^{(i)}=0\}}+2} \\
\end{align} %]]&gt;&lt;/script&gt;</content><author><name></name></author><summary type="html">Roadmap: Logistic Regression Learning Gradient Descent Newton’s Method Normal Equation Code Template k-Nearest Neighbors Statistical Setting for Classification Gaussian Discriminant Analysis 2 Types of Learning Algorithms &amp;amp; Bayes Theorem Naive Bayes Classifier Laplace Smoothing</summary></entry><entry><title type="html">SVM</title><link href="http://localhost:4000/ML/SVM/" rel="alternate" type="text/html" title="SVM" /><published>2019-12-01T21:29:53+08:00</published><updated>2019-12-01T21:29:53+08:00</updated><id>http://localhost:4000/ML/ML-SVM</id><content type="html" xml:base="http://localhost:4000/ML/SVM/">&lt;p&gt;Roadmap:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#margin&quot;&gt;Functional &amp;amp; Geometric Margins&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#lagrange&quot;&gt;Lagrange Duality&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#KKT&quot;&gt;KKT Conditions&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Problem with Classification:&lt;/p&gt;

    &lt;center&gt;&lt;img src=&quot;../../images/ML/SVM1.png&quot; width=&quot;300&quot; /&gt;&lt;/center&gt;

    &lt;p&gt;This is a binary classification. The circles &amp;amp; crosses are training examples with two different labels. The black line is the classifier, and it is able to classify “circle” and “cross”. For points like $\text{A}$ that are distant from the classifier, we are quite confident that they belong to “cross”.&lt;/p&gt;

    &lt;p&gt;However, what about $\text{B}$ and $\text{C}$ that are super close to the decision boundary? Based on this classifier, $\text{B}$ belongs to “cross” and $\text{C}$ belongs to “circle”, but how confident are we about our classifier? What if our classifier is just slightly off and $\text{C}$ was actually “cross”?&lt;/p&gt;

    &lt;center&gt;&lt;img src=&quot;../../images/ML/SVM2.png&quot; width=&quot;300&quot; /&gt;&lt;/center&gt;

    &lt;p&gt;This, is SVM in a nutshell.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt; &lt;a name=&quot;margin&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;margins&quot;&gt;Margins&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Functional Margin&lt;/strong&gt;&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  \hat{\gamma}^{(i)}=y^{(i)}(w^Tx+b)\ \ \ \ \ \ \|\ y\in\{-1,1\}
  \end{equation}&lt;/script&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Intuition: $\hat{\gamma}^{(i)}\uparrow\uparrow\ \rightarrow\text{confidence}\uparrow\uparrow$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;When $y=1\ \rightarrow w^Tx+b &amp;gt;&amp;gt; 0$.&lt;br /&gt;
  When $y=-1\rightarrow w^Tx+b &amp;lt;&amp;lt; 0$.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Problem with functional margin:&lt;/p&gt;

        &lt;p&gt;if $w\rightarrow kw$ and $b\rightarrow kb$ (where $k&amp;gt;0$), then $g(w^Tx+b)=g(k(w^Tx+b))$&lt;/p&gt;

        &lt;p&gt;but our $g(z)$ here follows:&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
g(z)=\begin{cases}
-1&amp; \text{if $z&lt;0$} \\
1&amp; \text{if $z&gt;0$} \\
\end{cases} %]]&gt;&lt;/script&gt;

        &lt;p&gt;that is, $z$ and $kz$ makes no difference for $g(z)$.&lt;/p&gt;

        &lt;p&gt;HOWEVER, the functional margin does change by a factor of $k$ here, meaning that a large functional margin does not necessarily represent a confident prediction in this case.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt; &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Geometric Margin&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Refer back to the figure above. If we want to find the distance between point $A$ and the decision boundary, which is $AA’=\gamma^{(i)}$, what should we do?&lt;/p&gt;

    &lt;center&gt;&lt;img src=&quot;../../images/ML/SVM3.png&quot; width=&quot;300&quot; /&gt;&lt;/center&gt;

    &lt;p&gt;We normalize $w$ to find the unit vector $\frac{w}{\lVert w \rVert}$, and we also have $A=x^{(i)}$. Because $AA’\parallel \overrightarrow{w}$, we can find $A’$ by:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  A'=x^{(i)}-\gamma^{(i)}\frac{w}{\lVert w \rVert}
  \end{equation}&lt;/script&gt;

    &lt;p&gt;and because $A’$ is on the decision boundary $w^Tx+b=0$, we get&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
  &amp;w^TA'+b=0 \\
  \Longrightarrow\ &amp;w^Tx^{(i)}+b=w^T\frac{w}{\lVert w \rVert}\gamma^{(i)} \ \ \ \ \ \ \ \ \ \bigg(w^T\frac{w}{\lVert w \rVert}=\frac{\lVert w \rVert^2}{\lVert w \rVert}\bigg) \\
  \Longrightarrow\ &amp;\gamma^{(i)}=\bigg(\frac{w}{\lVert w \rVert}\bigg)^Tx^{(i)}+\frac{b}{\lVert w \rVert}
  \end{align} %]]&gt;&lt;/script&gt;

    &lt;p&gt;and if we generalize it with both classes of $y^{(i)}$:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  \gamma^{(i)}=y^{(i)}\Bigg(\bigg(\frac{w}{\lVert w \rVert}\bigg)^Tx^{(i)}+\frac{b}{\lVert w \rVert}\Bigg)
  \end{equation}&lt;/script&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt; &lt;a name=&quot;lagrange&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;optimization-lagrange-duality&quot;&gt;Optimization: Lagrange Duality&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Constrained optimization problem&lt;/strong&gt;&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  \mathop{\min}_ {w} f(w)\ \ \text{s.t.}\ h_i(w)=0\ \ \forall i\in\{1,...,m\}
  \end{equation}&lt;/script&gt;

    &lt;p&gt;&lt;u&gt;Interpretation&lt;/u&gt;: Minimize a function $f(w)$ on the set $\{w\ |\ h_i(w)=0\ \forall i\in\{1,…,m\}\}$ where $w$ satisfies the equality constraints.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Lagrangian&lt;/strong&gt;&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  \mathcal{L}(w,\beta)=f(w)+\sum_{i=1}^{m}{\beta_ih_i(w)}
  \end{equation}&lt;/script&gt;

    &lt;p&gt;where $\beta_i=$ Lagrange multipliers, and then we solve it by $\frac{\partial{\mathcal{L}}}{\partial{w_i}}=0$ and $\frac{\partial{\mathcal{L}}}{\partial{\beta_i}}=0$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Generalized constrained optimization problem&lt;/strong&gt;&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
  \mathop{\min}_ {w} f(w)\ \ \text{s.t.}\ h_i(w)=0\ \ &amp;\forall i\in\{1,...,m\} \\
  g_i(w)\leq 0\ \ &amp;\forall i\in\{1,...,n\}
  \end{align} %]]&gt;&lt;/script&gt;

    &lt;p&gt;&lt;u&gt;Interpretation&lt;/u&gt;: Add an inequality constraint to the original optimization problem.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Generalized Lagrangian&lt;/strong&gt;&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  \mathcal{L}(w,\alpha,\beta)=f(w)+\sum_{i=1}^{m}{\beta_ih_i(w)}+\sum_{i=1}^{n}{\alpha_ig_i(w)}
  \end{equation}&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Primal optimization problem&lt;/strong&gt;&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  p^* =\mathop{\min}_ {w} \theta_{\mathcal{P}}(w)=\mathop{\min}_ {w} \mathop{\max}_ {\alpha,\beta:\alpha_i\geq0} \mathcal{L}(w,\alpha,\beta)
  \end{equation}&lt;/script&gt;

    &lt;p&gt;&lt;u&gt;Interpretation&lt;/u&gt;: Under the 2 primal constraints above, the maximum of our generalized lagrangian (labeled as $\theta_{\mathcal{P}}(w)$) is basically just $f(w)$ as long as $\alpha_i\geq0\ \forall i\in\{1,…,m\}$:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
  &amp;\sum_{i=1}^{m}{\beta_ih_i(w)}\longrightarrow\sum_{i=1}^{m}{\beta_i\cdot0}\longrightarrow0 \\
  &amp;\sum_{i=1}^{m}{\alpha_ig_i(w)}\xrightarrow{\alpha\geq0,g(w)\leq0}\sum_{i=1}^{m}{(+0\cdot-0)}\longrightarrow0
  \end{align} %]]&gt;&lt;/script&gt;

    &lt;p&gt;Therefore, this is just another way to write our generalized optimization problem.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Dual optimization problem&lt;/strong&gt;&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  d^* =\mathop{\max}_ {\alpha,\beta:\alpha_i\geq0} \theta_{\mathcal{D}}(\alpha,\beta)=\mathop{\max}_ {\alpha,\beta:\alpha_i\geq0} \mathop{\min}_ {w} \mathcal{L}(w,\alpha,\beta)
  \end{equation}&lt;/script&gt;

    &lt;p&gt;&lt;u&gt;Interpretation&lt;/u&gt;: This is basically the same problem as primal except that $\mathop{\max}$ and $\mathop{\min}$ are exchanged. However, their values are not necessarily equal. Instead, they follow the following relationship:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  d^* \leq p^*
  \end{equation}&lt;/script&gt;

    &lt;p&gt;The intuition is simple. Suppose we have a function $f(x,y)$, then:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align}
  \mathop{\min}_ {w} f(x,w)\leq f(x,y)\leq \mathop{\max}_ {v} f(v,y) \\
  \mathop{\min}_ {u} f(u,y)\leq f(x,y)\leq \mathop{\max}_ {t} f(x,t)
  \end{align}&lt;/script&gt;

    &lt;p&gt;This definitely holds for all functions in the world. Therefore, the following also holds:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
  \mathop{\max}_ {x} \big(\mathop{\min}_ {w} f(x,w)\big)\leq \mathop{\min}_ {y} \big(\mathop{\max}_ {v} f(v,y)\big)
  \end{equation}&lt;/script&gt;

    &lt;p&gt;which is basically saying that “$\mathop{\max}\mathop{\min}\leq\mathop{\min}\mathop{\max}$” for all multivariate functions, including our Lagrangian.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a name=&quot;KKT&quot;&gt;&lt;/a&gt;&lt;strong&gt;Karush-Kuhn-Tucker Conditions (KKT)&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Under the above assumptions, there must exist $w^*,\alpha^ *,\beta^ *$ so that&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;$w^*$ is the solution to the primal problem&lt;/li&gt;
          &lt;li&gt;$\alpha^ *,\beta^ *$ are the solution to the dual problem&lt;/li&gt;
          &lt;li&gt;$p^* =d^* =\mathcal{L}(w^* ,\alpha^ * ,\beta^ * )$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;KKT Conditions: $w^*,\alpha^ *,\beta^ *$ must satisfy:&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
  \frac{\partial}{\partial w_i}\mathcal{L}(w^*,\alpha^*,\beta^* )&amp;=0\ \ i=1,\cdots,n \\
  \frac{\partial}{\partial \beta_i}\mathcal{L}(w^*,\alpha^*,\beta^* )&amp;=0\ \ i=1,\cdots,l \\
  \alpha_i^* g_i(w^* )&amp;=0\ \ i=1,\cdots,k \\
  g_i(w^* )&amp;\leq0\ \ i=1,\cdots,k \\
  \alpha_i^* &amp;\geq0\ \ i=1,\cdots,k
  \end{align} %]]&gt;&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Roadmap: Functional &amp;amp; Geometric Margins Lagrange Duality KKT Conditions</summary></entry></feed>