<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-12-11T13:09:08+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Mr.Qâ€™s HUB</title><entry><title type="html">Machine Learning</title><link href="http://localhost:4000/ML/" rel="alternate" type="text/html" title="Machine Learning" /><published>2019-12-08T22:29:53+09:00</published><updated>2019-12-08T22:29:53+09:00</updated><id>http://localhost:4000/ML-welcome</id><content type="html" xml:base="http://localhost:4000/ML/">&lt;h2 id=&quot;machine-learning&quot;&gt;Machine Learning&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Regression&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a&gt;&lt;/a&gt;&lt;a href=&quot;/ML/Regression/&quot;&gt;Basics&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Improvements 1: Basics &amp;amp; Regularization&lt;/li&gt;
  &lt;li&gt;Improvements 2: Optimization &amp;amp; GD Algorithms&lt;/li&gt;
  &lt;li&gt;Improvements 3: Hyperparameter Tuning &amp;amp; Batch Normalization&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Classification&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Basics&lt;/li&gt;
  &lt;li&gt;Interesting CNNs&lt;/li&gt;
  &lt;li&gt;Object Detection&lt;/li&gt;
  &lt;li&gt;Face Recognition&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Clustering&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Basics&lt;/li&gt;
  &lt;li&gt;GRUs &amp;amp; LSTM&lt;/li&gt;
  &lt;li&gt;Word Embeddings&lt;/li&gt;
  &lt;li&gt;Applications in NLP&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Decision Tree&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Basics&lt;/li&gt;
  &lt;li&gt;GRUs &amp;amp; LSTM&lt;/li&gt;
  &lt;li&gt;Word Embeddings&lt;/li&gt;
  &lt;li&gt;Applications in NLP&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;SVM&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Basics&lt;/li&gt;
  &lt;li&gt;GRUs &amp;amp; LSTM&lt;/li&gt;
  &lt;li&gt;Word Embeddings&lt;/li&gt;
  &lt;li&gt;Applications in NLP&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Kernel Methods&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Basics&lt;/li&gt;
  &lt;li&gt;GRUs &amp;amp; LSTM&lt;/li&gt;
  &lt;li&gt;Word Embeddings&lt;/li&gt;
  &lt;li&gt;Applications in NLP&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Dimensionality Reduction&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Basics&lt;/li&gt;
  &lt;li&gt;GRUs &amp;amp; LSTM&lt;/li&gt;
  &lt;li&gt;Word Embeddings&lt;/li&gt;
  &lt;li&gt;Applications in NLP&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Boosting, Model Selection &amp;amp; Learning Theory&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Basics&lt;/li&gt;
  &lt;li&gt;GRUs &amp;amp; LSTM&lt;/li&gt;
  &lt;li&gt;Word Embeddings&lt;/li&gt;
  &lt;li&gt;Applications in NLP&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Machine Learning</summary></entry><entry><title type="html">Regression</title><link href="http://localhost:4000/ml/regression/" rel="alternate" type="text/html" title="Regression" /><published>2019-12-01T22:29:53+09:00</published><updated>2019-12-01T22:29:53+09:00</updated><id>http://localhost:4000/ml/ML-Regression</id><content type="html" xml:base="http://localhost:4000/ml/regression/">&lt;h2 id=&quot;notations&quot;&gt;Notations&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;$i$ th training example: $(x^{(i)},y^{(i)}) | x\in \mathbb{R}^n, y\in {0,1}$&lt;/li&gt;
  &lt;li&gt;$m$ = # training examples&lt;/li&gt;
  &lt;li&gt;$n$ = # features&lt;/li&gt;
  &lt;li&gt;$x_j$ = the $j$th feature (assume $x_0=1$)&lt;/li&gt;
  &lt;li&gt;$w_j$ = the weight for $j$th feature (assume $w_0=b:\sum_{i=1}^{n}w_i x_i+b = \sum_{i=0}^{n}w_i x_i$)&lt;/li&gt;
  &lt;li&gt;$\hat{y}=h(x)$= the hypothetical model&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;linear-regression&quot;&gt;Linear Regression&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Model&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
\hat{y}=\sum_{i=0}^{n}w_ix_i=w^Tx
\end{equation}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Cost Function (OLS)&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation*}
\mathcal{L}(w)=\frac{1}{2}\sum_{i=1}^{m}(\hat{y}^{(i)}-y^{(i)})^2
\end{equation*}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Gradient Descent&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation*}
w_j := w_j-\alpha\frac{\partial\mathcal{L}(w)}{\partial w_j}
\end{equation*}&lt;/script&gt;</content><author><name></name></author><summary type="html">Notations</summary></entry></feed>